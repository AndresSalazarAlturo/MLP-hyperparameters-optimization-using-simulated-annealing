@article{CHAUDHURI200011,
title = {Efficient training and improved performance of multilayer perceptron in pattern classification},
journal = {Neurocomputing},
volume = {34},
number = {1},
pages = {11-27},
year = {2000},
issn = {0925-2312},
doi = {https://doi.org/10.1016/S0925-2312(00)00305-2},
url = {https://www.sciencedirect.com/science/article/pii/S0925231200003052},
author = {B.B. Chaudhuri and U. Bhattacharya},
keywords = {Backpropagation algorithm, Multilayer perceptron, Faster training, Pattern classification},
abstract = {In pattern recognition problems, the convergence of backpropagation training algorithm of a multilayer perceptron is slow if the concerned classes have complex decision boundary. To improve the performance, we propose a technique, which at first cleverly picks up samples near the decision boundary without actually knowing the position of decision boundary. To choose the training samples, a larger set of data with known class label is considered. For each datum, its k-neighbours are found. If the datum is near the decision boundary, then all of these k-neighbours would not come from the same class. A training set, generated using this idea, results in quick and better convergence of the training algorithm. To get more symmetric neighbours, the nearest centroid neighbourhood (Chaudhuri, Pattern Recognition Lett. 17 (1996) 11â€“17) is used. The performance of the technique has been tested on synthetic data as well as speech vowel data in two Indian languages.}
}